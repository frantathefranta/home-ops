---
# yaml-language-server: $schema=https://taskfile.dev/schema.json
version: "3"

vars:
  KUBECONFORM_SCRIPT: "{{.SCRIPTS_DIR}}/kubeconform.sh"
  KUBERNETES_TEMPLATES_DIR: "{{.ROOT_DIR}}/.taskfiles/Kubernetes/templates"
  TIMENOW:
    sh: date +%Y%m%d-%H%M%S


tasks:

  resources:
    desc: Gather common resources in your cluster, useful when asking for support
    cmds:
      - for: { var: resource }
        cmd: kubectl get {{.ITEM}} {{.CLI_ARGS | default "-A"}}
    vars:
      resource: >-
        nodes
        gitrepositories
        kustomizations
        helmrepositories
        helmreleases
        certificates
        certificaterequests
        ingresses
        pods

  kubeconform:
    desc: Validate Kubernetes manifests with kubeconform
    cmd: bash {{.KUBECONFORM_SCRIPT}} {{.KUBERNETES_DIR}}
    preconditions:
      - { msg: "Missing kubeconform script", sh: "test -f {{.KUBECONFORM_SCRIPT}}" }

  race-ns-pod-security:
    aliases: [nsps]
    desc: While true loop labelling a given namespace with Pod Security labels, if external source creates namespace (e.g. Azure Arc's Helm apply with `--create-namespace`)
    vars:
      NS: &ns-fail '{{ or .NS (fail "Missing `NS` environment variable!") }}'
      PS: '{{ or .PS (fail "Missing `PS` environment variable!") }}'
    cmds:
      - while true; do kubectl label namespaces {{.NS}} "pod-security.kubernetes.io/enforce={{.PS}}" >/dev/null 2>/dev/null || true; kubectl label namespaces {{.NS}} "pod-security.kubernetes.io/enforce-version=latest" >/dev/null 2>/dev/null || true; done

  wait-pod-pending:
    aliases: [waitp]
    internal: true
    desc: Wait for a job's pod to change its status to pending
    vars:
      NAME: &name-fail '{{ or .NAME (fail "Missing `NAME` environment variable!") }}'
      NS: *ns-fail
    cmds:
      - |
        until [[ $(kubectl -n {{.NS}} get pod {{.NAME}} -o jsonpath='{.items[*].status.phase}') == "Pending" ]]; do sleep 1; done

  wait-pod-ready:
    internal: true
    desc: Wait for a pod to be ready
    vars:
      NAME: *name-fail
      NS: *ns-fail
    cmds:
      - until kubectl wait pod -n {{.NS}} {{.NAME}} --for=condition=Ready --timeout=1h; do sleep 1; done

  wait-finish:
    internal: true
    desc: Wait for a job's pod to change its status to pending
    vars:
      NAME: *name-fail
      NS: *ns-fail
      TYPE: '{{ .TYPE | default "job" }}'
      # WAIT_ARGS: '{{.WAIT_ARGS | default "echo \"{{.NAME}} is still running, logs:\" && kubectl -n {{.NS}} logs {{.NAME}} --since 2s -f;"}}'
    cmds:
      - |-
        until kubectl -n {{.NS}} wait {{.TYPE}}/{{.NAME}} --for condition=complete --timeout=2s; do
          echo "{{.NAME}} is still running, logs:" && kubectl -n {{.NS}} logs {{.TYPE}}/{{.NAME}} --since 2s -f || true;
        done


  iperf2:
    desc: Start a iperf2 server on one node, and iperf2 client on another node, to benchmark network performance.
    dir: "{{.KUBERNETES_TEMPLATES_DIR}}/iperf2"
    vars: &iperf2-vars
      SERVER_NAME: &iperf2-server-name 'iperf2-server-{{- .TIMENOW -}}'
      SERVER_NS: &iperf2-server-ns '{{ .SERVER_NS | default "default" }}'
      CLIENT_NAME: &iperf2-client-name 'iperf2-client-{{- .TIMENOW -}}'
      CLIENT_NS: &iperf2-client-ns '{{ .CLIENT_NS | default "default" }}'
      CLUSTER_DOMAIN: '{{ .CLUSTER_DOMAIN | default "cluster.local" }}'
      SERVER_PORT: '{{ .SERVER_PORT | default "5001" }}'
      SERVER_NODE: '{{ or .SERVER_NODE (fail "Missing `SERVER_NODE` environment variable!") }}'
      CLIENT_NODE: '{{ or .CLIENT_NODE (fail "Missing `CLIENT_NODE` environment variable!") }}'
      SERVER_ARGS: '{{ .SERVER_ARGS | default "" }}'
      CLIENT_ARGS: '{{ .CLIENT_ARGS | default "" }}'
    env: *iperf2-vars
    cmds:
      - cat "{{.KUBERNETES_TEMPLATES_DIR}}/iperf2/server.yaml" | envsubst | kubectl apply -f -
      - defer: cat "{{.KUBERNETES_TEMPLATES_DIR}}/iperf2/server.yaml" | envsubst | kubectl delete -f -
      - task: wait-pod-ready
        vars:
          NAME: '-l job-name={{.SERVER_NAME}}'
          NS: '{{.SERVER_NS}}'
      - cat "{{.KUBERNETES_TEMPLATES_DIR}}/iperf2/client.yaml" | envsubst | kubectl apply -f -
      - defer: cat "{{.KUBERNETES_TEMPLATES_DIR}}/iperf2/client.yaml" | envsubst | kubectl delete -f -
      - task: wait-finish
        vars:
          NAME: '{{.CLIENT_NAME}}'
          NS: '{{.CLIENT_NS}}'
  .reset:
    internal: true
    cmd: rm -rf {{.KUBERNETES_DIR}}

  # https://docs.github.com/en/enterprise-cloud@latest/actions/hosting-your-own-runners/managing-self-hosted-runners-with-actions-runner-controller/deploying-runner-scale-sets-with-actions-runner-controller#upgrading-arc
  upgrade-arc:
    desc: Upgrade the ARC
    cmds:
      - helm -n actions-runner-system uninstall home-ops-runner
      - helm -n actions-runner-system uninstall actions-runner-controller
      - sleep 5
      - flux -n actions-runner-system reconcile hr actions-runner-controller
      - flux -n actions-runner-system reconcile hr home-ops-runner
    preconditions:
      - which flux helm
